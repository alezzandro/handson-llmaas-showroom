[#maas_introduction]
= Setting Up Model-as-a-Service Infrastructure

== Introduction: The Hidden Cost of Infrastructure-as-a-Service

As a **platform engineer**, you may inherit clusters filled with GPU nodes and eager teams. But when infrastructure is self-service with no clear guardrails in place, problems can quickly emerge:

- Very few people know how to request or size GPU resources correctly
- Teams duplicate work by deploying their own models repeatedly
- Expensive GPUs sit idle or overloaded
- Overall infrastructure costs spiral with no accountability
- Most people just need model access - not to manage their own GPUs.

[.bordershadow]
image::images/02/iaas.png[]

== Models-as-a-Service: A Better Abstraction for AI at Scale

To address these challenges as a platform engineer, you will design a centralized, reusable, and secure model-serving layer:

* Models are deployed and maintained by platform teams
** Lifecycle managed: versioning, rollback, testing
* Served through an API Gateway
** Authenticated, rate-limited, observable
* Developers consume the models without touching hardware
** Build apps, agents, or features - powered by AI
* Resources are pooled and shared
** Avoid waste, ensure fairness and reduce cost

[.bordershadow]
image::../assets/images/02/maas.png[]

== Module 1 Goals: Step into the role of the platform engineer

In this first module, you will take your first step into the role of a platform engineer enabling Generative AI at scale.

You will:

* Explore the architecture of OpenShift AI and how it supports enterprise model serving
* Configure an API Gateway to expose the model endpoint securely to end users

By the end, you will understand how to transform raw infrastructure into a scalable, manageable Model-as-a-Service (MaaS) foundation that others in your organization can build on.